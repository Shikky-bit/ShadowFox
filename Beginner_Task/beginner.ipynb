{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91657c82",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1 â€” Install deps (if needed) & GPU check\n",
    "!pip install -q torch torchvision pillow matplotlib scikit-learn\n",
    "\n",
    "import torch, sys\n",
    "print(\"Python:\", sys.version.splitlines()[0])\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "    except:\n",
    "        print(\"CUDA available but device name fetch failed.\")\n",
    "else:\n",
    "    print(\"No GPU detected. Make sure runtime -> Change runtime type -> GPU.\")\n",
    "# Cell 2 â€” Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"Drive mounted at /content/drive\")\n",
    "# Step 4 â€” CLEAN dataloaders (ImageFolder or CIFAR fallback)\n",
    "import os, random, numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2\n",
    "DATASET_PATH = \"/content/drive/MyDrive/dataset\"   # change if needed\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.15,0.15,0.15,0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def get_dataloaders(path=DATASET_PATH, batch_size=BATCH_SIZE):\n",
    "    train_path = Path(path) / \"train\"\n",
    "    val_path   = Path(path) / \"val\"\n",
    "\n",
    "    if train_path.exists() and val_path.exists():\n",
    "        print(\"ðŸ”¥ Using ImageFolder dataset from:\", path)\n",
    "        train_ds = datasets.ImageFolder(str(train_path), transform=train_tf)\n",
    "        val_ds   = datasets.ImageFolder(str(val_path),   transform=val_tf)\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "        val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        return train_loader, val_loader, train_ds.classes\n",
    "\n",
    "    print(\"âš ï¸  ImageFolder dataset not found. Falling back to CIFAR10 (cat/dog/car).\")\n",
    "    cifar_tf = transforms.Compose([transforms.Resize(224), transforms.ToTensor(), transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "    cifar_train = datasets.CIFAR10(root=\"/content/cifar\", train=True, download=True, transform=cifar_tf)\n",
    "    cifar_test  = datasets.CIFAR10(root=\"/content/cifar\", train=False, download=True, transform=cifar_tf)\n",
    "\n",
    "    def is_kept(label):\n",
    "        return label in [3,5,1,9]\n",
    "\n",
    "    train_idx = [i for i, (_,y) in enumerate(cifar_train) if is_kept(y)][:2000]\n",
    "    test_idx  = [i for i, (_,y) in enumerate(cifar_test)  if is_kept(y)][:1000]\n",
    "\n",
    "    def remap_label(lbl):\n",
    "        if lbl == 3: return 0   # cat\n",
    "        if lbl == 5: return 1   # dog\n",
    "        return 2                # car\n",
    "\n",
    "    class CIFARFiltered(torch.utils.data.Dataset):\n",
    "        def __init__(self, base_ds, idxs):\n",
    "            self.base = base_ds\n",
    "            self.idxs = idxs\n",
    "        def __len__(self): return len(self.idxs)\n",
    "        def __getitem__(self, i):\n",
    "            x, lbl = self.base[self.idxs[i]]\n",
    "            return x, remap_label(lbl)\n",
    "\n",
    "    train_ds = CIFARFiltered(cifar_train, train_idx)\n",
    "    val_ds   = CIFARFiltered(cifar_test,  test_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    return train_loader, val_loader, [\"cat\",\"dog\",\"car\"]\n",
    "\n",
    "# Run to create variables\n",
    "train_loader, val_loader, classes = get_dataloaders()\n",
    "print(\"\\nClasses:\", classes)\n",
    "print(\"Train batches:\", len(train_loader))\n",
    "print(\"Val batches:\", len(val_loader))\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"Sample batch shape:\", xb.shape, yb.shape)\n",
    "# STEP 5 â€” Build Model (ResNet18 fine-tuning)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "def build_model(num_classes, freeze_backbone=False):\n",
    "    # Load pretrained weights (new PyTorch 2.0 API)\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "    # If you want faster training at first: freeze backbone\n",
    "    if freeze_backbone:\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"fc\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    # Replace final layer for our number of classes\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(model.fc.in_features, num_classes)\n",
    "    )\n",
    "\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "print(\"Classes detected:\", classes)   # must exist from Step 4\n",
    "\n",
    "# Build the model\n",
    "model = build_model(len(classes))\n",
    "\n",
    "print(\"\\nModel created successfully!\")\n",
    "print(\"Output classes:\", len(classes))\n",
    "# STEP 6 â€” Train the model and save best checkpoint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time, copy\n",
    "\n",
    "NUM_EPOCHS = 8         # you can increase later\n",
    "LR = 1e-3\n",
    "SAVE_PATH = \"/content/drive/MyDrive/best_imagetagger.pth\"   # model save location\n",
    "\n",
    "def train_model(model, train_loader, val_loader, classes, epochs=NUM_EPOCHS, lr=LR):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nðŸš€ Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        # -------------------\n",
    "        # TRAINING PHASE\n",
    "        # -------------------\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = output.argmax(1)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total_samples += x.size(0)\n",
    "\n",
    "        train_acc = total_correct / total_samples\n",
    "        train_loss = total_loss / total_samples\n",
    "\n",
    "        # -------------------\n",
    "        # VALIDATION PHASE\n",
    "        # -------------------\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                preds = output.argmax(1)\n",
    "\n",
    "                val_loss += loss.item() * x.size(0)\n",
    "                val_correct += (preds == y).sum().item()\n",
    "                val_samples += x.size(0)\n",
    "\n",
    "        val_acc = val_correct / val_samples\n",
    "        val_loss = val_loss / val_samples\n",
    "\n",
    "        print(f\"   Train Acc: {train_acc:.4f}   |   Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # SAVE BEST MODEL\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save({\"model_state\": best_wts, \"classes\": classes}, SAVE_PATH)\n",
    "            print(f\"   ðŸ’¾ Saved new best model! ({SAVE_PATH})\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(\"\\nâœ… Training complete!\")\n",
    "    print(\"Best Validation Accuracy:\", best_acc)\n",
    "\n",
    "    # load best weights before returning\n",
    "    model.load_state_dict(best_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "# -------- RUN TRAINING --------\n",
    "model = train_model(model, train_loader, val_loader, classes)\n",
    "# STEP 7 â€” Evaluation + confusion matrix + show examples\n",
    "# Run after training (expects: model or saved checkpoint, val_loader, classes, DEVICE)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "CKPT_PATH = \"/content/drive/MyDrive/best_imagetagger.pth\"\n",
    "OUT_DIR = \"/content/drive/MyDrive/imagetagger_eval\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# 1) load the best checkpoint if present (otherwise use current model variable)\n",
    "if os.path.exists(CKPT_PATH):\n",
    "    print(\"Loading checkpoint from:\", CKPT_PATH)\n",
    "    ck = torch.load(CKPT_PATH, map_location=DEVICE)\n",
    "    ck_classes = ck.get(\"classes\", None)\n",
    "    if ck_classes is not None and ck_classes != classes:\n",
    "        print(\"Warning: checkpoint classes differ from current `classes` variable. Using checkpoint's classes.\")\n",
    "        classes = ck_classes\n",
    "    # build model of matching size and load weights (safe load)\n",
    "    try:\n",
    "        temp_model = model  # try to reuse existing model variable shape\n",
    "        temp_model.load_state_dict(ck[\"model_state\"])\n",
    "        temp_model.eval()\n",
    "        eval_model = temp_model\n",
    "    except Exception as e:\n",
    "        # fallback: rebuild then load\n",
    "        from torchvision import models\n",
    "        import torch.nn as nn\n",
    "        eval_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        eval_model.fc = torch.nn.Sequential(torch.nn.Dropout(0.4), torch.nn.Linear(eval_model.fc.in_features, len(classes)))\n",
    "        eval_model.load_state_dict(ck[\"model_state\"])\n",
    "        eval_model = eval_model.to(DEVICE)\n",
    "else:\n",
    "    print(\"No checkpoint found at\", CKPT_PATH, \" â€” using current `model` in memory.\")\n",
    "    eval_model = model\n",
    "\n",
    "eval_model.eval()\n",
    "\n",
    "# 2) run through validation set and collect preds & probs\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []   # top1 prob for each sample\n",
    "sample_images = []  # store some examples for display (pil images + meta)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        out = eval_model(xb)\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        top1 = probs.argmax(1).cpu().numpy().tolist()\n",
    "        top1p = probs.max(1)[0].cpu().numpy().tolist()\n",
    "        all_preds.extend(top1)\n",
    "        all_labels.extend(yb.numpy().tolist())\n",
    "        all_probs.extend(top1p)\n",
    "        # save a few images and their preds for display (convert from tensor)\n",
    "        for i in range(min(3, xb.size(0))):\n",
    "            # inverse normalize for display\n",
    "            t = xb[i].cpu()\n",
    "            inv_norm = torch.tensor([[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "                                     [1/0.229, 1/0.224, 1/0.225]])\n",
    "            mean = torch.tensor([0.485,0.456,0.406]).view(3,1,1)\n",
    "            std  = torch.tensor([0.229,0.224,0.225]).view(3,1,1)\n",
    "            img = t * std + mean\n",
    "            img = (img.clamp(0,1).permute(1,2,0).numpy() * 255).astype(np.uint8)\n",
    "            sample_images.append({\n",
    "                \"pil\": Image.fromarray(img),\n",
    "                \"true\": int(yb[i].item()),\n",
    "                \"pred\": int(top1[i]),\n",
    "                \"prob\": float(top1p[i])\n",
    "            })\n",
    "\n",
    "# 3) classification report + confusion matrix\n",
    "print(\"\\n== Classification report ==\")\n",
    "report = classification_report(all_labels, all_preds, target_names=classes, digits=4, output_dict=True)\n",
    "print(classification_report(all_labels, all_preds, target_names=classes, digits=4))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"\\nConfusion matrix:\\n\", cm)\n",
    "\n",
    "# Save report to CSV/JSON\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(os.path.join(OUT_DIR, \"classification_report.csv\"))\n",
    "pd.DataFrame(cm, index=classes, columns=classes).to_csv(os.path.join(OUT_DIR, \"confusion_matrix.csv\"))\n",
    "print(\"\\nSaved evaluation CSVs to:\", OUT_DIR)\n",
    "\n",
    "# 4) plot confusion matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.colorbar()\n",
    "ticks = np.arange(len(classes))\n",
    "plt.xticks(ticks, classes, rotation=45)\n",
    "plt.yticks(ticks, classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, cm[i,j], ha=\"center\", va=\"center\", color=\"white\" if cm[i,j] > cm.max()/2 else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"confusion_matrix.png\"))\n",
    "plt.show()\n",
    "\n",
    "# 5) show some correct & misclassified examples (up to 8)\n",
    "print(\"\\n== Sample examples (true -> pred : prob) ==\")\n",
    "show_count = 0\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "for item in sample_images[:8]:\n",
    "    ax = fig.add_subplot(2,4,show_count+1)\n",
    "    ax.imshow(item[\"pil\"])\n",
    "    title = f\"{classes[item['true']]} â†’ {classes[item['pred']]} : {item['prob']:.2f}\"\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "    show_count += 1\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6) summary print and done\n",
    "acc_overall = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "print(f\"\\nOverall validation accuracy: {acc_overall:.4f}\")\n",
    "print(\"Saved files in:\", OUT_DIR)\n",
    "!ls -lh /content/drive/MyDrive\n",
    "IMG_PATH = \"/content/drive/MyDrive/car1.png\"\n",
    "# or\n",
    "IMG_PATH = \"/content/drive/MyDrive/myphoto.jpg\"\n",
    "# List all images in MyDrive\n",
    "import glob\n",
    "\n",
    "files = glob.glob(\"/content/drive/MyDrive/*.*\")\n",
    "\n",
    "print(\"Files in MyDrive:\")\n",
    "for f in files:\n",
    "    print(f)\n",
    "IMG_PATH = \"/content/drive/MyDrive/car.jpeg\"\n",
    "# Auto-pick latest image in MyDrive and predict (single cell)\n",
    "import glob, os, torch\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive\"\n",
    "CKPT_PATH = \"/content/drive/MyDrive/best_imagetagger.pth\"\n",
    "IMG_EXTS = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".tiff\"]\n",
    "\n",
    "# 1) find latest image file in MyDrive\n",
    "candidates = []\n",
    "for ext in IMG_EXTS:\n",
    "    candidates += glob.glob(os.path.join(DRIVE_ROOT, f\"*{ext}\"))\n",
    "    candidates += glob.glob(os.path.join(DRIVE_ROOT, f\"**/*{ext}\"), recursive=True)\n",
    "candidates = list(set(candidates))  # unique\n",
    "\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(f\"No image files found under {DRIVE_ROOT}. Drop an image there (MyDrive root) and re-run.\")\n",
    "\n",
    "# choose most recently modified\n",
    "latest = max(candidates, key=os.path.getmtime)\n",
    "print(\"Using latest image:\", latest)\n",
    "\n",
    "# 2) check checkpoint\n",
    "if not os.path.exists(CKPT_PATH):\n",
    "    raise FileNotFoundError(f\"Model checkpoint not found at {CKPT_PATH}. Run training cell to create it.\")\n",
    "\n",
    "# 3) load checkpoint and rebuild model safely\n",
    "ck = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "classes = ck.get(\"classes\", None)\n",
    "if classes is None:\n",
    "    raise RuntimeError(\"Checkpoint missing 'classes'. Can't rebuild model.\")\n",
    "\n",
    "# rebuild model\n",
    "model_pred = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "model_pred.fc = nn.Sequential(nn.Dropout(0.4), nn.Linear(model_pred.fc.in_features, len(classes)))\n",
    "model_pred.load_state_dict(ck[\"model_state\"])\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_pred = model_pred.to(DEVICE).eval()\n",
    "\n",
    "# 4) prepare transform (re-define val_tf lightly to ensure availability)\n",
    "from torchvision import transforms\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# 5) predict\n",
    "img = Image.open(latest).convert(\"RGB\")\n",
    "x = val_tf(img).unsqueeze(0).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    out = model_pred(x)\n",
    "    probs = F.softmax(out, dim=1)[0]\n",
    "    top_p, top_i = probs.topk(min(3, len(classes)))\n",
    "results = [(classes[i], float(top_p[j])) for j,i in enumerate(top_i)]\n",
    "\n",
    "# 6) show results\n",
    "print(\"\\nðŸ”¥ Top predictions (class â†’ confidence):\")\n",
    "for cls, p in results:\n",
    "    print(f\"  {cls} â†’ {p:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Predicted: {results[0][0]} ({results[0][1]:.2f})\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
